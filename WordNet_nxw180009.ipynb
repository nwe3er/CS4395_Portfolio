{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# WordNet\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "outputs": [],
   "source": [
    "### Imports\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.wsd import lesk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.book import *\n",
    "import math\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Summary of Wordnet\n",
    "WordNet is a lexical database of semantic relations between words in more than 200 languages. WordNet links words into semantic relations including synonyms, hyponyms, and meronyms. The synonyms are grouped into synsets with short definitions and usage examples. The original goal of Wordnet was to support theories of human semantic memory that suggested that people organize concepts mentally in some kind of hierarchy."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## This program selects a noun, then outputs all synsets."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chosen noun is phone.\n",
      "Sysnset list: [Synset('telephone.n.01'), Synset('phone.n.02'), Synset('earphone.n.01'), Synset('call.v.03')]\n"
     ]
    }
   ],
   "source": [
    "print(\"The chosen noun is phone.\")\n",
    "\n",
    "print('Sysnset list:', wn.synsets('phone'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### This section selects one synset from the list of synsets. Then it extracts its definition, usage examples, and lemmas."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phone - Electronic Equipment That Converts Sound Into Electrical Signals That Can Be Transmitted Over Distances And Then Converts Received Signals Back Into Sounds \n",
      "\n",
      "Example: ['I talked to him on the telephone'] \n",
      "\n",
      "[Lemma('telephone.n.01.telephone'), Lemma('telephone.n.01.phone'), Lemma('telephone.n.01.telephone_set')]\n"
     ]
    }
   ],
   "source": [
    "# Definition\n",
    "selection = wn.synset('telephone.n.01')\n",
    "print('Phone -', selection.definition().title(), '\\n')\n",
    "\n",
    "# Example\n",
    "print('Example:',selection.examples(), '\\n')\n",
    "\n",
    "# Lemmas\n",
    "print(selection.lemmas())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Using the same noun, traverse up the WordNet hierarchy as far as it can, outputting the synsets as it goes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('electronic_equipment.n.01')\n",
      "Synset('equipment.n.01')\n",
      "Synset('instrumentality.n.03')\n",
      "Synset('artifact.n.01')\n",
      "Synset('whole.n.02')\n",
      "Synset('object.n.01')\n",
      "Synset('physical_entity.n.01')\n",
      "Synset('entity.n.01')\n"
     ]
    }
   ],
   "source": [
    "hyp = selection.hypernyms()[0]\n",
    "top = wn.synset('entity.n.01')\n",
    "while hyp:\n",
    "    print(hyp)\n",
    "    if hyp == top:\n",
    "        break\n",
    "    if hyp.hypernyms():\n",
    "        hyp = hyp.hypernyms()[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## How WordNet is organized with nouns\n",
    "Nouns in WordNet have a max hypernym of 'entity.n.01', where the nouns are organized into a hierarchy structure with the max being on the very top. It seems that all the nouns are hyponyms of this one synset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### The following code outputs the following (or an empty list if none exist): hypernyms,\n",
    "#### hyponyms, meronyms, holonyms, antonym."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypernyms:  [Synset('electronic_equipment.n.01')] \n",
      "\n",
      "hyponyms:  [Synset('desk_phone.n.01'), Synset('dial_telephone.n.01'), Synset('extension.n.10'), Synset('handset.n.01'), Synset('pay-phone.n.01'), Synset('radiotelephone.n.02'), Synset('speakerphone.n.01')] \n",
      "\n",
      "meronyms:  [Synset('mouthpiece.n.02'), Synset('telephone_receiver.n.01')] \n",
      "\n",
      "holonyms:  [Synset('telephone_system.n.01')] \n",
      "\n",
      "antonym:  []\n"
     ]
    }
   ],
   "source": [
    "# hypernyms\n",
    "print('hypernyms: ', selection.hypernyms(), '\\n')\n",
    "\n",
    "# hyponyms\n",
    "print('hyponyms: ', selection.hyponyms(), '\\n')\n",
    "\n",
    "# meronyms\n",
    "print('meronyms: ', selection.part_meronyms(), '\\n')\n",
    "\n",
    "# holonyms\n",
    "print('holonyms: ', selection.part_holonyms(), '\\n')\n",
    "\n",
    "# antonym\n",
    "print('antonym: ', selection.lemmas()[0].antonyms())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### This program selects a verb, then outputs all synsets."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chosen verb is run.\n",
      "Sysnset list: [Synset('run.n.01'), Synset('test.n.05'), Synset('footrace.n.01'), Synset('streak.n.01'), Synset('run.n.05'), Synset('run.n.06'), Synset('run.n.07'), Synset('run.n.08'), Synset('run.n.09'), Synset('run.n.10'), Synset('rivulet.n.01'), Synset('political_campaign.n.01'), Synset('run.n.13'), Synset('discharge.n.06'), Synset('run.n.15'), Synset('run.n.16'), Synset('run.v.01'), Synset('scat.v.01'), Synset('run.v.03'), Synset('operate.v.01'), Synset('run.v.05'), Synset('run.v.06'), Synset('function.v.01'), Synset('range.v.01'), Synset('campaign.v.01'), Synset('play.v.18'), Synset('run.v.11'), Synset('tend.v.01'), Synset('run.v.13'), Synset('run.v.14'), Synset('run.v.15'), Synset('run.v.16'), Synset('prevail.v.03'), Synset('run.v.18'), Synset('run.v.19'), Synset('carry.v.15'), Synset('run.v.21'), Synset('guide.v.05'), Synset('run.v.23'), Synset('run.v.24'), Synset('run.v.25'), Synset('run.v.26'), Synset('run.v.27'), Synset('run.v.28'), Synset('run.v.29'), Synset('run.v.30'), Synset('run.v.31'), Synset('run.v.32'), Synset('run.v.33'), Synset('run.v.34'), Synset('ply.v.03'), Synset('hunt.v.01'), Synset('race.v.02'), Synset('move.v.13'), Synset('melt.v.01'), Synset('ladder.v.01'), Synset('run.v.41')]\n"
     ]
    }
   ],
   "source": [
    "print(\"The chosen verb is run.\")\n",
    "\n",
    "print('Sysnset list:', wn.synsets('run'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### This section selects one synset from the list of synsets. Then it extracts its definition, usage examples, and lemmas."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run - Move Fast By Using One'S Feet, With One Foot Off The Ground At Any Given Time \n",
      "\n",
      "Example: [\"Don't run--you'll be out of breath\", 'The children ran to the store'] \n",
      "\n",
      "[Lemma('run.v.01.run')]\n"
     ]
    }
   ],
   "source": [
    "# Definition\n",
    "selection2 = wn.synset('run.v.01')\n",
    "print('Run -', selection2.definition().title(), '\\n')\n",
    "\n",
    "# Example\n",
    "print('Example:',selection2.examples(), '\\n')\n",
    "\n",
    "# Lemmas\n",
    "print(selection2.lemmas())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Using the same verb, traverse up the WordNet hierarchy as far as it can, outputting the synsets as it goes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('run.v.01')\n",
      "Synset('travel_rapidly.v.01')\n",
      "Synset('travel.v.01')\n"
     ]
    }
   ],
   "source": [
    "x = selection2\n",
    "while True:\n",
    "    print(x)\n",
    "    if x.hypernyms():\n",
    "        x = x.hypernyms()[0]\n",
    "    else:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### How WordNet is organized with nouns\n",
    "Unlike nouns, for verbs there is no uniform top level synset. They can still be grouped into different hierarchies, but there\n",
    "isn't a max level that groups them together as we saw for the nouns example with 'entity.n.01'."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### This code uses morphy to find as many different forms of the word"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "None\n",
      "run\n",
      "run\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# selected word is run\n",
    "run = 'run'\n",
    "print(wn.morphy(run))\n",
    "print(wn.morphy(run, wn.ADJ))\n",
    "print(wn.morphy(run, wn.VERB))\n",
    "print(wn.morphy(run, wn.NOUN))\n",
    "print(wn.morphy(run, wn.ADJ_SAT))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### This portion selects two words that I think might be similar and find the specific synsets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Girl:  [Synset('girl.n.01'), Synset('female_child.n.01'), Synset('daughter.n.01'), Synset('girlfriend.n.02'), Synset('girl.n.05')] \n",
      "\n",
      "Female:  [Synset('female.n.01'), Synset('female.n.02'), Synset('female.a.01'), Synset('female.s.02'), Synset('female.s.03')] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Girl: ', wn.synsets('Girl'), '\\n')\n",
    "\n",
    "print('Female: ', wn.synsets('Female'), '\\n')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### This program runs the Wu-Palmer similarity metric and the Lesk algorithm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wu-Palmer similarity metric: 0.6666666666666666\n",
      "Lesk Algorithm: Synset('girlfriend.n.02')\n"
     ]
    }
   ],
   "source": [
    "girl = wn.synset('girl.n.01')\n",
    "female = wn.synset('female.n.01')\n",
    "\n",
    "print('Wu-Palmer similarity metric:', wn.wup_similarity(girl,female))\n",
    "\n",
    "# Lesk Algorithm to disambiguate the meaning of football\n",
    "sent = ['Are', 'you', 'a', 'girl']\n",
    "print('Lesk Algorithm:', lesk(sent, 'girl'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A similarity score between two word senses can be extracted from WordNet, where the similarity ranges from 0 (little similarity) to 1 (identity). We see that the words girl and female are similar. The Lesk Algorithm was a bit funny and disambiguated the word girl to girlfriend.n.02.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SentiWordNet\n",
    "What is SentiWordNet?\n",
    "- SentiWordNet is a lexical resource built on top of WordNet that assigns 3 sentiment scores\n",
    "- For each synset: positivity, negativity, and objectivity.\n",
    "\n",
    "What is a use case?\n",
    "- An example of using this would be to see if a Twitter tweet is negative or violating.\n",
    "\n",
    "The Program below select an emotionally charged word, find its senti-synsets and output the polarity scores for each word. Then it makes up a sentence and outputs the polarity for each word in the sentence"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive score:  0.0 \n",
      "\n",
      "Negative score:  0.625 \n",
      "\n",
      "Object score:  0.375 \n",
      "\n",
      "Word ---> I\n",
      "<iodine.n.01: PosScore=0.0 NegScore=0.0>\n",
      "neg score: 0.0 \tpos score: 0.0 \tobj score: 1.0 \n",
      "\n",
      "Word ---> hate\n",
      "<hate.n.01: PosScore=0.125 NegScore=0.375>\n",
      "neg score: 0.375 \tpos score: 0.125 \tobj score: 0.5 \n",
      "\n",
      "Word ---> having\n",
      "<have.v.01: PosScore=0.25 NegScore=0.0>\n",
      "neg score: 0.0 \tpos score: 0.25 \tobj score: 0.75 \n",
      "\n",
      "Word ---> wake\n",
      "<aftermath.n.01: PosScore=0.0 NegScore=0.0>\n",
      "neg score: 0.0 \tpos score: 0.0 \tobj score: 1.0 \n",
      "\n",
      "Word ---> up\n",
      "<up.v.01: PosScore=0.0 NegScore=0.0>\n",
      "neg score: 0.0 \tpos score: 0.0 \tobj score: 1.0 \n",
      "\n",
      "Word ---> early\n",
      "<early.a.01: PosScore=0.0 NegScore=0.0>\n",
      "neg score: 0.0 \tpos score: 0.0 \tobj score: 1.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(wn.synsets('anger'))\n",
    "\n",
    "# emotionally charged word\n",
    "anger = swn.senti_synset('hurt.n.01')\n",
    "\n",
    "# scores\n",
    "print(\"Positive score: \", anger.pos_score(), '\\n')\n",
    "print(\"Negative score: \", anger.neg_score(), '\\n')\n",
    "print(\"Object score: \", anger.obj_score(), '\\n')\n",
    "\n",
    "sent = 'I hate having to wake up early'\n",
    "neg = 0\n",
    "pos = 0\n",
    "tokens = sent.split()\n",
    "for token in tokens:\n",
    "    syn_list = list(swn.senti_synsets(token))\n",
    "    if syn_list:\n",
    "        syn = syn_list[0]\n",
    "        neg += syn.neg_score()\n",
    "        pos += syn.pos_score()\n",
    "        print('Word --->', token)\n",
    "        print(str(syn))\n",
    "        print('neg score:', syn.neg_score(), '\\tpos score:',syn.pos_score(), '\\tobj score:', syn.obj_score(), '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Observatioons of the scores\n",
    "It was pretty cool to use this functionality to see how words get scored. For the word 'anger', it seemed accurate to give it a negative score. The word 'hate' has a 0.125 score of being positive, which was eye catching. The utility of knowing these scores in an NLP application is huge! Although some words were scored incorrectly, I believe we could someday have models that are more ideal and very accurate.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Collocations\n",
    "When two or more words usually occur together with a frequency greater than chance would suggest, the words may form a collocation. A key indication that two words form a collocation is that you cannot substitute synonyms. An examples would be 'fast food'. These two words are used together and does not mean that the food is fast. These pairs of words are known as collocation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; fellow citizens; years ago; four years; Federal\n",
      "Government; General Government; American people; Vice President; God\n",
      "bless; Chief Justice; one another; fellow Americans; Old World;\n",
      "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
      "tribes; public debt; foreign nations\n",
      "None\n",
      "\n",
      "American people: 0.00399002493765586\n",
      "\n",
      "American: 0.025735660847880298\n",
      "\n",
      "people: 0.06264339152119701\n",
      "\n",
      "pmi:  1.3073947068021263\n",
      "\n",
      "Indian tribes: 0.000598503740648379\n",
      "\n",
      "Indian: 0.0010972568578553616\n",
      "\n",
      "tribes: 0.000598503740648379\n",
      "\n",
      "pmi:  12.568848591758554\n"
     ]
    }
   ],
   "source": [
    "# Output collocations for text4, the Inaugural corpus\n",
    "print(text4.collocations())\n",
    "\n",
    "x = ' '.join(text4.tokens)\n",
    "y = len(set(text4))\n",
    "\n",
    "# Calculation of mutual information\n",
    "phrase = x.count('American people')/ y\n",
    "phrase2 = x.count('American')/ y\n",
    "phrase3 = x.count('people')/ y\n",
    "pmi = math.log2(phrase/(phrase2*phrase3))\n",
    "\n",
    "# print results\n",
    "print('\\nAmerican people:', phrase)\n",
    "print('\\nAmerican:', phrase2)\n",
    "print('\\npeople:', phrase3)\n",
    "print('\\npmi: ', pmi)\n",
    "\n",
    "# Calculation of mutual information\n",
    "phrase4 = x.count('Indian tribes')/ y\n",
    "phrase5 = x.count('Indian')/ y\n",
    "phrase6 = x.count('tribes')/ y\n",
    "pmi = math.log2(phrase/(phrase5*phrase6))\n",
    "\n",
    "# print results\n",
    "print('\\nIndian tribes:', phrase4)\n",
    "print('\\nIndian:', phrase5)\n",
    "print('\\ntribes:', phrase6)\n",
    "print('\\npmi: ', pmi)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looking at the results, the pmi for 'American people' was 1.3073947068021263 and 12.568848591758554 for Indian tribes; therefore, according to collocations, Indian tribes is more likely to be a collocations.\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}